{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 67478,
          "databundleVersionId": 7734014,
          "sourceType": "competition"
        },
        {
          "sourceId": 7638551,
          "sourceType": "datasetVersion",
          "datasetId": 4451631
        }
      ],
      "dockerImageVersionId": 30648,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'ultra-wide-band-pose-prediction:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F67478%2F7734014%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240218%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240218T100913Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D7cf14ea4e398e90a1a774af0fe9a6068624dadff699e33354a369e7007451ce78b02ec77f50f7e9b922e66ec21df28cd700376191478f375740211b08b238dfd81dab55549b47eac5b1bf741b6fbfbdc97b6244d6375d7e6bc576dd1431f910210e92f80a213e5c44b1ca8670f9f2d44a6da84afc425430a3c137e87ac6afcdebba36e09589187cec9cc359897eed0106da0f88e5448532f3cc6e7649138b311e8d7319df2e280990d026bafe2eb8af60e27cc53a689386eac3bb98150a3d53811b8e6c5ea1d9c1a64900c883969463c284829a9826d904eba326fa289da0ef53858a35d974c779b168eb9987b444510fa3578ee191cb31883d4e969311e17ae,signal-to-img:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4451631%2F7638551%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240218%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240218T100914Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Da455fe068eb0277b9eed240928dfa4d103fee845b1d279127eae4c45f420fef99e0df4fbd35af7b26bbe48b0ba2ddc42904835f8af2771659c2cf8c54ecf0ed30630c3a3ca1ab53b4132d1edc837c5aaf23dab4efdfe65c29393bc14e454ab9efee6c68c4ca20bdf1e5ab8ccda9561fbe55f08833abd9e74aa53ca2de95023f2509bbacbc6d810808229373dbc35245dc36e5411a5da121cd479da2dfcefd9835dd440ce9db94d5add2555e8651119bf6e0474f42ac1a00a4c6614bfc1c94da89de400fc09798a7aa9f8b97f79e15f2d51a6ad382e5625aa8fd6b57127a80be4bddfa57a09db2e0c3f93a4bf1677e2b8624b18d83c41fffd413dda33ee8e10f1'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "hKKpY9PosQVI"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "ECSYT4-lsQVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# baseline"
      ],
      "metadata": {
        "id": "hdlPlBaSsQVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "import numpy as np\n",
        "from scipy import fftpack as fft\n",
        "import cv2\n",
        "import pandas as pd\n",
        "\n",
        "classes = [\"fall\", \"jump\", \"not_fall\", \"run\", \"run_sit\", \"sit_run\", \"walk\"]\n",
        "\n",
        "overlap = 128\n",
        "n_rd_history = 256\n",
        "overlap_count = 0\n",
        "min_iq = 0\n",
        "max_iq = 0.05\n",
        "min_rf = 0\n",
        "max_rf = 45\n",
        "\n",
        "\n",
        "class CSVDopplerDatagen(Dataset):\n",
        "    def __init__(self,\n",
        "                 csv='/kaggle/input/ultra-wide-band-pose-prediction/annotations.csv',\n",
        "                 src='/kaggle/input/ultra-wide-band-pose-prediction/train/train'):\n",
        "        self.csv = pd.read_csv(csv).fillna(-1)\n",
        "        self.src = src\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.csv)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.csv.iloc[idx]\n",
        "        iq = np.load(os.path.join(\n",
        "            self.src,\n",
        "            row['id'] + '.npy'\n",
        "        ))\n",
        "        if iq.shape[0] > 2560:\n",
        "            iq = iq[-2560:]\n",
        "        range_frequency = self.range_frequency([iq])[0]\n",
        "        image = np.stack((\n",
        "            iq / max_iq,\n",
        "            range_frequency / max_rf,\n",
        "            np.zeros_like(iq),\n",
        "        ))\n",
        "        return image, row['class']\n",
        "\n",
        "    @staticmethod\n",
        "    def range_frequency(datas):\n",
        "        Range_frequency_frame = []\n",
        "        for data in datas:\n",
        "            jitter = 1e-10\n",
        "            noise_threshold = -45\n",
        "            dB = True\n",
        "            rd_history = np.hanning(data.shape[0])[:, None] * np.array(data)\n",
        "            # Range-Doppler\n",
        "            rd = fft.fft(rd_history, axis=0)\n",
        "            rd = fft.fftshift(rd, axes=0)\n",
        "            rd = abs(rd)\n",
        "            if dB:\n",
        "                rd = 20 * np.log10(rd + jitter)\n",
        "                rd[rd < noise_threshold] = noise_threshold\n",
        "            Range_frequency_frame.append(rd)\n",
        "        return np.stack(Range_frequency_frame)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    dset = CSVDopplerDatagen()\n",
        "    min_rf = float('inf')\n",
        "    min_iq = float('inf')\n",
        "    max_rf = -float('inf')\n",
        "    max_iq = -float('inf')\n",
        "    lengths = {2560: 0, 7680: 0}\n",
        "    for i in range(len(dset)):\n",
        "        data, _ = dset[i]\n",
        "        # min_iq = min(min_iq, np.abs(data[0]).min())\n",
        "        # max_iq = max(max_iq, np.abs(data[0]).max())\n",
        "        # min_rf = min(min_rf, np.abs(data[1]).min())\n",
        "        # max_rf = max(max_rf, np.abs(data[1]).max())\n",
        "        lengths[data.shape[1]] += 1\n",
        "    x = dset[0]\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T13:36:17.451548Z",
          "iopub.execute_input": "2024-02-16T13:36:17.452285Z",
          "iopub.status.idle": "2024-02-16T13:36:35.771479Z",
          "shell.execute_reply.started": "2024-02-16T13:36:17.452253Z",
          "shell.execute_reply": "2024-02-16T13:36:35.770604Z"
        },
        "trusted": true,
        "id": "fMYQwi3EsQVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from timm.models import convnext\n",
        "\n",
        "class ViTCls(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = convnext.convnext_base(pretrained=True)\n",
        "        self.cls = nn.Linear(self.encoder.num_features, 7)\n",
        "\n",
        "    def forward(self, images):\n",
        "        x = self.encoder.forward_features(images)\n",
        "        x = self.encoder.forward_head(x, pre_logits=True)\n",
        "        y = self.cls(x)\n",
        "        return y\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T13:37:16.333622Z",
          "iopub.execute_input": "2024-02-16T13:37:16.334546Z",
          "iopub.status.idle": "2024-02-16T13:37:20.226785Z",
          "shell.execute_reply.started": "2024-02-16T13:37:16.334506Z",
          "shell.execute_reply": "2024-02-16T13:37:20.225813Z"
        },
        "trusted": true,
        "id": "98uhpXq0sQVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# signal to img (do it in colab)"
      ],
      "metadata": {
        "id": "DoQ2EsKasQVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "trusted": true,
        "id": "PD13mdJ1sQVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install accelerate -U"
      ],
      "metadata": {
        "trusted": true,
        "id": "SIbFHHMqsQVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "import timm\n",
        "import timm.optim\n",
        "import timm.scheduler\n",
        "from timm.data import ImageDataset, create_dataset, create_loader\n",
        "from timm.data.transforms_factory import create_transform\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import glob"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-17T14:23:48.101113Z",
          "iopub.execute_input": "2024-02-17T14:23:48.10199Z",
          "iopub.status.idle": "2024-02-17T14:23:48.108199Z",
          "shell.execute_reply.started": "2024-02-17T14:23:48.101955Z",
          "shell.execute_reply": "2024-02-17T14:23:48.107278Z"
        },
        "trusted": true,
        "id": "stkqRWc-sQVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.fftpack as fft\n",
        "def Range_frequency(datas):\n",
        "    Range_frequency_frame = []\n",
        "    for data in datas:\n",
        "        dB = True\n",
        "        # Range-Doppler\n",
        "        rd = fft.fft(data, axis=0)\n",
        "        rd = fft.fftshift(rd, axes=0)\n",
        "        rd = abs(rd)\n",
        "        DBrd = 20 * np.log10(rd+1e-10)\n",
        "        Range_frequency_frame.append(DBrd)\n",
        "    return np.stack(Range_frequency_frame)\n",
        "\n",
        "def range_time(IQ_data):\n",
        "    n_rd_history = 256\n",
        "    frame = []\n",
        "    frames = []\n",
        "    for iqini in IQ_data:\n",
        "        if len(frame)<n_rd_history:\n",
        "            frame.append(iqini)\n",
        "        else:\n",
        "            frames.append(np.copy(frame))\n",
        "            frame.append(iqini)\n",
        "            frame = frame[1::]\n",
        "    return np.stack(frames)"
      ],
      "metadata": {
        "id": "smO7_2zwsQVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "annotations = pd.read_csv(\"/content/annotations.csv\")\n",
        "annotations.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-17T13:07:39.880817Z",
          "iopub.execute_input": "2024-02-17T13:07:39.881186Z",
          "iopub.status.idle": "2024-02-17T13:07:39.897Z",
          "shell.execute_reply.started": "2024-02-17T13:07:39.881142Z",
          "shell.execute_reply": "2024-02-17T13:07:39.89589Z"
        },
        "trusted": true,
        "id": "Lnes8bw0sQVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "labels = []\n",
        "\n",
        "for index in range(annotations.shape[0]):\n",
        "    file_path = '/content/train/train/{0}.npy'.format(annotations['id'][index])\n",
        "    np_data = np.load(file_path)\n",
        "    data.append(np_data)\n",
        "    labels.append(annotations['class'][index])\n",
        "\n",
        "len(data), len(data[0])"
      ],
      "metadata": {
        "id": "dT3cPzTOsQVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.1, random_state=42, stratify=labels)\n",
        "len(X_train), len(X_val)"
      ],
      "metadata": {
        "id": "beK1avXNsQVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_folder = '/content/drive/MyDrive/Colab Notebooks/data/signal_train/'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "for i in tqdm(range(len(X_train))):\n",
        "    train = X_train[i]\n",
        "    train = range_time(train)\n",
        "    train = Range_frequency(train)\n",
        "    train = train.reshape(train.shape[0] * train.shape[1], train.shape[2])\n",
        "    label = y_train[i]\n",
        "    label_folder = os.path.join(output_folder, str(label))\n",
        "    os.makedirs(label_folder, exist_ok=True)\n",
        "    file_path = os.path.join(label_folder, str(i) + '.png')\n",
        "    fig = plt.figure(frameon=False)\n",
        "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
        "    ax.set_axis_off()\n",
        "    fig.add_axes(ax)\n",
        "    ax.imshow(np.abs(train.T), aspect=\"auto\")\n",
        "    fig.savefig(file_path)\n",
        "    fig.clear()\n",
        "    plt.close(fig)"
      ],
      "metadata": {
        "id": "VlTMb0IzsQVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_folder = '/content/drive/MyDrive/Colab Notebooks/data/signal_val/'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "for i in tqdm(range(len(X_val))):\n",
        "    train = X_val[i]\n",
        "    train = range_time(train)\n",
        "    train = Range_frequency(train)\n",
        "    train = train.reshape(train.shape[0] * train.shape[1], train.shape[2])\n",
        "    label = y_val[i]\n",
        "    label_folder = os.path.join(output_folder, str(label))\n",
        "    os.makedirs(label_folder, exist_ok=True)\n",
        "    file_path = os.path.join(label_folder, str(i) + '.png')\n",
        "    fig = plt.figure(frameon=False)\n",
        "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
        "    ax.set_axis_off()\n",
        "    fig.add_axes(ax)\n",
        "    ax.imshow(np.abs(train.T), aspect=\"auto\")\n",
        "    fig.savefig(file_path)\n",
        "    fig.clear()\n",
        "    plt.close(fig)"
      ],
      "metadata": {
        "id": "ZMdNrooSsQVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_test = []\n",
        "names = []\n",
        "\n",
        "for index in range(sam_submit.shape[0]):\n",
        "    file_path = '/kaggle/input/ultra-wide-band-pose-prediction/test/test/{0}.npy'.format(sam_submit['id'][index])\n",
        "    np_data = np.load(file_path)\n",
        "    data_test.append(np_data)\n",
        "    names.append(sam_submit['id'][index])\n",
        "\n",
        "len(data_test)"
      ],
      "metadata": {
        "id": "1aEV8QzHsQVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_folder = '/content/drive/MyDrive/Colab Notebooks/data/signal_test/'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "from tqdm import tqdm\n",
        "\n",
        "for i in tqdm(range(len(data_test))):\n",
        "    train = data_test[i]\n",
        "    train = range_time(train)\n",
        "    train = Range_frequency(train)\n",
        "    train = train.reshape(train.shape[0] * train.shape[1], train.shape[2])\n",
        "    file_path = os.path.join(output_folder, names[i] + '.png')\n",
        "    fig = plt.figure(frameon=False)\n",
        "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
        "    ax.set_axis_off()\n",
        "    fig.add_axes(ax)\n",
        "    ax.imshow(np.abs(train.T), aspect=\"auto\")\n",
        "    fig.savefig(file_path)\n",
        "    fig.clear()\n",
        "    plt.close(fig)"
      ],
      "metadata": {
        "id": "kFEw2yz-sQVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LeVIT"
      ],
      "metadata": {
        "id": "Cs-EWpFWsQVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load data"
      ],
      "metadata": {
        "id": "zECw401-sQVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from torchvision import transforms\n",
        "\n",
        "X_train = []\n",
        "y_train = []\n",
        "size = (224, 224)\n",
        "directory_path = '/kaggle/input/signal-to-img/data/signal_train'\n",
        "folder_names = [folder for folder in os.listdir(directory_path) if os.path.isdir(os.path.join(directory_path, folder))]\n",
        "\n",
        "def importdatasets_name(name):\n",
        "    input_dir = \"/kaggle/input/signal-to-img/data/signal_train/\" + name\n",
        "\n",
        "    input_img_paths_png = sorted(\n",
        "        [\n",
        "            os.path.join(input_dir, fname)\n",
        "            for fname in os.listdir(input_dir)\n",
        "            if fname.endswith(\".png\")\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    for i in input_img_paths_png:\n",
        "      try:\n",
        "        image = cv2.imread(i)\n",
        "        image = cv2.resize(image, size)\n",
        "\n",
        "        X_train.extend([image])\n",
        "        y_train.extend([name])\n",
        "      except:\n",
        "        pass\n",
        "\n",
        "for i in tqdm(folder_names):\n",
        "  importdatasets_name(i)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T18:47:06.721642Z",
          "iopub.execute_input": "2024-02-16T18:47:06.722019Z",
          "iopub.status.idle": "2024-02-16T18:47:10.489316Z",
          "shell.execute_reply.started": "2024-02-16T18:47:06.721987Z",
          "shell.execute_reply": "2024-02-16T18:47:10.488133Z"
        },
        "trusted": true,
        "id": "HQg9gAihsQVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names, y_train = np.unique(np.array(y_train), return_inverse=True)\n",
        "_, y_val = np.unique(np.array(y_val), return_inverse=True)\n",
        "class_names"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T18:47:12.201894Z",
          "iopub.execute_input": "2024-02-16T18:47:12.202762Z",
          "iopub.status.idle": "2024-02-16T18:47:12.211388Z",
          "shell.execute_reply.started": "2024-02-16T18:47:12.202728Z",
          "shell.execute_reply": "2024-02-16T18:47:12.210355Z"
        },
        "trusted": true,
        "id": "mhLv6vdhsQVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from torchvision import transforms\n",
        "\n",
        "X_val = []\n",
        "y_val = []\n",
        "size = (224, 224)\n",
        "directory_path = '/kaggle/input/signal-to-img/data/signal_val'\n",
        "folder_names = [folder for folder in os.listdir(directory_path) if os.path.isdir(os.path.join(directory_path, folder))]\n",
        "\n",
        "def importdatasets_name(name):\n",
        "    input_dir = \"/kaggle/input/signal-to-img/data/signal_val/\" + name\n",
        "\n",
        "    input_img_paths_png = sorted(\n",
        "        [\n",
        "            os.path.join(input_dir, fname)\n",
        "            for fname in os.listdir(input_dir)\n",
        "            if fname.endswith(\".png\")\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    for i in input_img_paths_png:\n",
        "      try:\n",
        "        image = cv2.imread(i)\n",
        "        image = cv2.resize(image, size)\n",
        "\n",
        "        X_val.extend([image])\n",
        "        y_val.extend([name])\n",
        "      except:\n",
        "        pass\n",
        "\n",
        "for i in tqdm(folder_names):\n",
        "  importdatasets_name(i)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T18:46:19.714012Z",
          "iopub.execute_input": "2024-02-16T18:46:19.714646Z",
          "iopub.status.idle": "2024-02-16T18:46:20.215006Z",
          "shell.execute_reply.started": "2024-02-16T18:46:19.714612Z",
          "shell.execute_reply": "2024-02-16T18:46:20.21408Z"
        },
        "trusted": true,
        "id": "cEwMPTxFsQVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.stack(X_train)\n",
        "X_val = np.stack(X_val)\n",
        "X_train.shape, X_val.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T18:47:18.443337Z",
          "iopub.execute_input": "2024-02-16T18:47:18.444003Z",
          "iopub.status.idle": "2024-02-16T18:47:18.473766Z",
          "shell.execute_reply.started": "2024-02-16T18:47:18.443971Z",
          "shell.execute_reply": "2024-02-16T18:47:18.472654Z"
        },
        "trusted": true,
        "id": "tilobntksQVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(X_train[3], aspect=\"auto\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T18:47:24.842725Z",
          "iopub.execute_input": "2024-02-16T18:47:24.843071Z",
          "iopub.status.idle": "2024-02-16T18:47:25.132913Z",
          "shell.execute_reply.started": "2024-02-16T18:47:24.843043Z",
          "shell.execute_reply": "2024-02-16T18:47:25.129597Z"
        },
        "trusted": true,
        "id": "NF8jTmv0sQVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model & train"
      ],
      "metadata": {
        "id": "JEz95fxIsQVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, images, labels=None):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = torch.tensor(self.images[idx]).permute(2, 0, 1).float()\n",
        "        if self.labels is not None:\n",
        "            label = torch.tensor(self.labels[idx])\n",
        "            return {\"pixel_values\": image, \"label\": label}\n",
        "        else:\n",
        "            return {\"pixel_values\": image}\n",
        "\n",
        "train_dataset = CustomDataset(X_train, y_train)\n",
        "val_dataset = CustomDataset(X_val, y_val)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T18:47:34.193772Z",
          "iopub.execute_input": "2024-02-16T18:47:34.194517Z",
          "iopub.status.idle": "2024-02-16T18:47:34.203304Z",
          "shell.execute_reply.started": "2024-02-16T18:47:34.194468Z",
          "shell.execute_reply": "2024-02-16T18:47:34.202214Z"
        },
        "trusted": true,
        "id": "hr3zUe46sQVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "import torch.nn as nn\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "class Vit(nn.Module):\n",
        "    def __init__(self, pretrained=True, num_classes=7):\n",
        "        super(Vit, self).__init__()\n",
        "        self.model = timm.create_model(\"levit_384.fb_dist_in1k\", pretrained=pretrained, num_classes=num_classes)\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, pixel_values, labels=None):\n",
        "        outputs = self.model(pixel_values)\n",
        "        logits = outputs\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss = self.loss_fn(logits, labels)\n",
        "        return {\"logits\": logits, \"loss\": loss}\n",
        "\n",
        "model = Vit()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T19:30:23.738399Z",
          "iopub.execute_input": "2024-02-16T19:30:23.739322Z",
          "iopub.status.idle": "2024-02-16T19:30:25.865212Z",
          "shell.execute_reply.started": "2024-02-16T19:30:23.739287Z",
          "shell.execute_reply": "2024-02-16T19:30:25.864107Z"
        },
        "trusted": true,
        "id": "WzbmJRT0sQVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import default_data_collator\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./levit_training_output\",\n",
        "    num_train_epochs=100,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=500,\n",
        "    eval_steps=500,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    learning_rate=1e-5,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    data_collator=default_data_collator,\n",
        "    tokenizer=None,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T19:30:34.171272Z",
          "iopub.execute_input": "2024-02-16T19:30:34.171664Z",
          "iopub.status.idle": "2024-02-16T19:38:37.67777Z",
          "shell.execute_reply.started": "2024-02-16T19:30:34.171632Z",
          "shell.execute_reply": "2024-02-16T19:38:37.676709Z"
        },
        "trusted": true,
        "id": "ay330ArbsQVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "\n",
        "results = trainer.predict(val_dataset)\n",
        "predicted_labels = torch.argmax(torch.tensor(results.predictions), axis=1).numpy()\n",
        "accuracy = accuracy_score(y_val, predicted_labels)\n",
        "f1 = f1_score(y_val, predicted_labels, average=\"weighted\")\n",
        "\n",
        "print(f\"Validation Accuracy: {accuracy}\")\n",
        "print(f\"Validation F1 Score: {f1}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T19:38:43.707281Z",
          "iopub.execute_input": "2024-02-16T19:38:43.70767Z",
          "iopub.status.idle": "2024-02-16T19:38:43.892743Z",
          "shell.execute_reply.started": "2024-02-16T19:38:43.707639Z",
          "shell.execute_reply": "2024-02-16T19:38:43.891004Z"
        },
        "trusted": true,
        "id": "D5p3nLf7sQVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(confusion_matrix(y_val, predicted_labels), annot=True, cmap='RdPu', fmt='g')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T19:38:59.987624Z",
          "iopub.execute_input": "2024-02-16T19:38:59.98837Z",
          "iopub.status.idle": "2024-02-16T19:39:00.31141Z",
          "shell.execute_reply.started": "2024-02-16T19:38:59.988341Z",
          "shell.execute_reply": "2024-02-16T19:39:00.310361Z"
        },
        "trusted": true,
        "id": "zylpppJasQVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test"
      ],
      "metadata": {
        "id": "GXjFk091sQVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dir = \"/kaggle/input/signal-to-img/data/signal_test\"\n",
        "\n",
        "input_img_paths_png = sorted(\n",
        "    [\n",
        "        os.path.join(input_dir, fname)\n",
        "        for fname in os.listdir(input_dir)\n",
        "        if fname.endswith(\".png\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"Number of samples:\", len(input_img_paths_png))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T19:39:07.980772Z",
          "iopub.execute_input": "2024-02-16T19:39:07.981135Z",
          "iopub.status.idle": "2024-02-16T19:39:08.001292Z",
          "shell.execute_reply.started": "2024-02-16T19:39:07.981106Z",
          "shell.execute_reply": "2024-02-16T19:39:08.000202Z"
        },
        "trusted": true,
        "id": "DyA2YuK0sQVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = []\n",
        "\n",
        "for i in tqdm(input_img_paths_png):\n",
        "  image = cv2.imread(i)\n",
        "  image = cv2.resize(image, (224, 224))\n",
        "  X_test.append(image)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T19:39:09.772531Z",
          "iopub.execute_input": "2024-02-16T19:39:09.773366Z",
          "iopub.status.idle": "2024-02-16T19:39:11.157574Z",
          "shell.execute_reply.started": "2024-02-16T19:39:09.773334Z",
          "shell.execute_reply": "2024-02-16T19:39:11.155653Z"
        },
        "trusted": true,
        "id": "Qj9FE9gtsQVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = np.stack(X_test)\n",
        "X_test.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T19:39:11.89362Z",
          "iopub.execute_input": "2024-02-16T19:39:11.894018Z",
          "iopub.status.idle": "2024-02-16T19:39:11.907937Z",
          "shell.execute_reply.started": "2024-02-16T19:39:11.893989Z",
          "shell.execute_reply": "2024-02-16T19:39:11.907007Z"
        },
        "trusted": true,
        "id": "opI01zZEsQVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(X_test[3], aspect=\"auto\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T19:39:13.533131Z",
          "iopub.execute_input": "2024-02-16T19:39:13.533516Z",
          "iopub.status.idle": "2024-02-16T19:39:13.801609Z",
          "shell.execute_reply.started": "2024-02-16T19:39:13.533465Z",
          "shell.execute_reply": "2024-02-16T19:39:13.800465Z"
        },
        "trusted": true,
        "id": "DEFe_YxAsQVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TestDataset(Dataset):\n",
        "    def __init__(self, images, labels=None):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = torch.tensor(self.images[idx]).permute(2, 0, 1).float()\n",
        "        return {\"pixel_values\": torch.tensor(image)}\n",
        "\n",
        "test_dataset = TestDataset(X_test)\n",
        "model.to(\"cpu\")\n",
        "model.eval()\n",
        "\n",
        "predicted_labels = []\n",
        "with torch.no_grad():\n",
        "    for sample in tqdm(test_dataset):\n",
        "        pixel_values = sample[\"pixel_values\"].unsqueeze(0)\n",
        "        logits = model(pixel_values)[\"logits\"]\n",
        "        predictions = torch.argmax(logits, dim=1).item()\n",
        "        predicted_labels.append(predictions)\n",
        "predicted_labels = np.array(predicted_labels)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T19:39:16.436261Z",
          "iopub.execute_input": "2024-02-16T19:39:16.43665Z",
          "iopub.status.idle": "2024-02-16T19:39:26.609213Z",
          "shell.execute_reply.started": "2024-02-16T19:39:16.43662Z",
          "shell.execute_reply": "2024-02-16T19:39:26.608426Z"
        },
        "trusted": true,
        "id": "LrQMvepasQVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_labels"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T19:39:26.610899Z",
          "iopub.execute_input": "2024-02-16T19:39:26.61117Z",
          "iopub.status.idle": "2024-02-16T19:39:26.618519Z",
          "shell.execute_reply.started": "2024-02-16T19:39:26.611146Z",
          "shell.execute_reply": "2024-02-16T19:39:26.617603Z"
        },
        "trusted": true,
        "id": "H8B7sjSosQVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ans = class_names[predicted_labels]\n",
        "print(len(ans[ans == '0']))\n",
        "print(len(ans[ans == '1']))\n",
        "print(len(ans[ans == '2']))\n",
        "print(len(ans[ans == '3']))\n",
        "print(len(ans[ans == '4']))\n",
        "print(len(ans[ans == '5']))\n",
        "print(len(ans[ans == '6']))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T19:39:32.164129Z",
          "iopub.execute_input": "2024-02-16T19:39:32.164507Z",
          "iopub.status.idle": "2024-02-16T19:39:32.181469Z",
          "shell.execute_reply.started": "2024-02-16T19:39:32.164466Z",
          "shell.execute_reply": "2024-02-16T19:39:32.180428Z"
        },
        "trusted": true,
        "id": "o8H3vs-dsQVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(\"/kaggle/input/ultra-wide-band-pose-prediction/sample_submission.csv\")\n",
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T19:39:35.175023Z",
          "iopub.execute_input": "2024-02-16T19:39:35.175822Z",
          "iopub.status.idle": "2024-02-16T19:39:35.193387Z",
          "shell.execute_reply.started": "2024-02-16T19:39:35.175786Z",
          "shell.execute_reply": "2024-02-16T19:39:35.192485Z"
        },
        "trusted": true,
        "id": "ntBRy_KisQVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(df)):\n",
        "    file_name = df['id'][i]\n",
        "    for j in range(len(df)):\n",
        "        img_path = input_img_paths_png[j].replace(\"/kaggle/input/signal-to-img/data/signal_test/\", \"\").replace(\".png\", \"\")\n",
        "        if file_name == img_path:\n",
        "            df.loc[i, 'class'] = ans[j]\n",
        "            break\n",
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T19:39:37.478457Z",
          "iopub.execute_input": "2024-02-16T19:39:37.478835Z",
          "iopub.status.idle": "2024-02-16T19:39:37.527526Z",
          "shell.execute_reply.started": "2024-02-16T19:39:37.478808Z",
          "shell.execute_reply": "2024-02-16T19:39:37.526072Z"
        },
        "trusted": true,
        "id": "dDIi9ltesQV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('levit384_100ep.csv', index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T19:40:17.14757Z",
          "iopub.execute_input": "2024-02-16T19:40:17.147934Z",
          "iopub.status.idle": "2024-02-16T19:40:17.156156Z",
          "shell.execute_reply.started": "2024-02-16T19:40:17.147905Z",
          "shell.execute_reply": "2024-02-16T19:40:17.154996Z"
        },
        "trusted": true,
        "id": "5rMpSj3psQV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# resnet"
      ],
      "metadata": {
        "id": "k-D5beYrsQV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "train_files = glob.glob(\"/kaggle/input/signal-to-img/data/signal_train/**/*.png\")\n",
        "val_files = glob.glob(\"/kaggle/input/signal-to-img/data/signal_val/**/*.png\")\n",
        "test_files = glob.glob(\"/kaggle/input/signal-to-img/data/signal_test/*.png\")\n",
        "\n",
        "transforms = {\n",
        "    \"train\": T.Compose([\n",
        "        T.Resize((224, 224), interpolation=T.InterpolationMode.BICUBIC),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=torch.tensor([0.4850, 0.4560, 0.4060]), std=torch.tensor([0.2290, 0.2240, 0.2250]))\n",
        "    ]),\n",
        "    \"test\": T.Compose([\n",
        "        T.Resize((224, 224), interpolation=T.InterpolationMode.BICUBIC),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=torch.tensor([0.4850, 0.4560, 0.4060]), std=torch.tensor([0.2290, 0.2240, 0.2250]))\n",
        "    ])\n",
        "}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-17T15:43:40.186422Z",
          "iopub.execute_input": "2024-02-17T15:43:40.187392Z",
          "iopub.status.idle": "2024-02-17T15:43:40.217039Z",
          "shell.execute_reply.started": "2024-02-17T15:43:40.187345Z",
          "shell.execute_reply": "2024-02-17T15:43:40.216119Z"
        },
        "trusted": true,
        "id": "Rr6mRSM5sQV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "import timm.optim\n",
        "import timm.scheduler\n",
        "from timm.data import ImageDataset, create_dataset, create_loader\n",
        "from timm.data.transforms_factory import create_transform\n",
        "\n",
        "train_dataset = ImageDataset(\"/kaggle/input/signal-to-img/data/signal_train\", transform=transforms[\"train\"])\n",
        "val_dataset = ImageDataset(\"/kaggle/input/signal-to-img/data/signal_val\", transform=transforms[\"train\"])\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-17T15:43:42.350329Z",
          "iopub.execute_input": "2024-02-17T15:43:42.350702Z",
          "iopub.status.idle": "2024-02-17T15:43:42.373873Z",
          "shell.execute_reply.started": "2024-02-17T15:43:42.350672Z",
          "shell.execute_reply": "2024-02-17T15:43:42.373121Z"
        },
        "trusted": true,
        "id": "2AlaVAKqsQV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = timm.create_model(\"seresnextaa101d_32x8d.sw_in12k_ft_in1k\", pretrained=True, num_classes=7).to(device)"
      ],
      "metadata": {
        "trusted": true,
        "id": "3rGc_DvosQV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 20\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = timm.optim.create_optimizer_v2(model, opt=\"AdamW\", lr=1e-3)\n",
        "optimizer = timm.optim.Lookahead(optimizer, alpha=0.5, k=5)\n",
        "scheduler = timm.scheduler.create_scheduler_v2(optimizer, num_epochs=num_epochs)[0]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-17T17:11:10.524626Z",
          "iopub.execute_input": "2024-02-17T17:11:10.525017Z",
          "iopub.status.idle": "2024-02-17T17:11:10.532545Z",
          "shell.execute_reply.started": "2024-02-17T17:11:10.524985Z",
          "shell.execute_reply": "2024-02-17T17:11:10.531507Z"
        },
        "trusted": true,
        "id": "QmYTafmasQV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "info = {\n",
        "    \"metric_train\": [],\n",
        "    \"metric_val\": [],\n",
        "    \"train_loss\": [],\n",
        "    \"val_loss\": [],\n",
        "    \"best_metric_val\": -999,\n",
        "}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-17T17:11:12.483385Z",
          "iopub.execute_input": "2024-02-17T17:11:12.484125Z",
          "iopub.status.idle": "2024-02-17T17:11:12.489867Z",
          "shell.execute_reply.started": "2024-02-17T17:11:12.484091Z",
          "shell.execute_reply": "2024-02-17T17:11:12.488709Z"
        },
        "trusted": true,
        "id": "MJovZtJssQV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss_epoch = []\n",
        "    val_loss_epoch = []\n",
        "\n",
        "    train_preds = []\n",
        "    train_targets = []\n",
        "\n",
        "    val_preds = []\n",
        "    val_targets = []\n",
        "\n",
        "    num_updates = epoch * len(train_dataloader)\n",
        "\n",
        "    # Train Loop\n",
        "    model.train()\n",
        "    for batch in tqdm(train_dataloader):\n",
        "        inputs, targets = batch\n",
        "        outputs = model(inputs.to(device))\n",
        "        loss = criterion(outputs, targets.to(device))\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step_update(num_updates=num_updates)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        train_loss_epoch.append(loss.item())\n",
        "        train_preds += outputs.argmax(-1).detach().cpu().tolist()\n",
        "        train_targets += targets.tolist()\n",
        "\n",
        "    optimizer.sync_lookahead()\n",
        "    scheduler.step(epoch + 1)\n",
        "\n",
        "    # Eval Loop\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_dataloader):\n",
        "            inputs, targets = batch\n",
        "            outputs = model(inputs.to(device))\n",
        "            loss = criterion(outputs, targets.to(device))\n",
        "\n",
        "            # Log Values\n",
        "            val_loss_epoch.append(loss.item())\n",
        "            val_preds += outputs.argmax(-1).detach().cpu().tolist()\n",
        "            val_targets += targets.tolist()\n",
        "\n",
        "    # Log Data\n",
        "    metric_train = f1_score(train_targets, train_preds, average=\"macro\")\n",
        "    metric_val = f1_score(val_targets, val_preds, average=\"macro\")\n",
        "\n",
        "    info[\"metric_train\"].append(metric_train)\n",
        "    info[\"metric_val\"].append(metric_val)\n",
        "\n",
        "    info[\"train_loss\"].append(np.average(train_loss_epoch))\n",
        "    info[\"val_loss\"].append(np.average(val_loss_epoch))\n",
        "\n",
        "    if metric_val > info[\"best_metric_val\"] and np.average(val_loss_epoch) <= min(info[\"val_loss\"]):\n",
        "        print(\"New Best Score have been save!\")\n",
        "        info[\"best_metric_val\"] = metric_val\n",
        "        torch.save(model, \"checkpoint.pt\")\n",
        "\n",
        "    print(info)\n",
        "    print(f\"Epoch: {epoch} | Metric: {metric_val} | Training Loss: {np.average(train_loss_epoch)} | Validation Loss: {np.average(val_loss_epoch)}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "11OR1eTysQV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = torch.load(\"/kaggle/working/checkpoint.pt\")\n",
        "predictions = []\n",
        "references = []\n",
        "\n",
        "loaded_model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(val_dataloader):\n",
        "        inputs, targets = batch\n",
        "        outputs = loaded_model(inputs.to(device))\n",
        "\n",
        "        # Log Values\n",
        "        predictions += outputs.argmax(-1).detach().cpu().tolist()\n",
        "        references += targets.tolist()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-17T16:48:07.222992Z",
          "iopub.execute_input": "2024-02-17T16:48:07.223743Z",
          "iopub.status.idle": "2024-02-17T16:48:09.078245Z",
          "shell.execute_reply.started": "2024-02-17T16:48:07.22371Z",
          "shell.execute_reply": "2024-02-17T16:48:09.07733Z"
        },
        "trusted": true,
        "id": "p13L7CrbsQV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(references, predictions)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-17T16:48:10.828774Z",
          "iopub.execute_input": "2024-02-17T16:48:10.829461Z",
          "iopub.status.idle": "2024-02-17T16:48:11.133654Z",
          "shell.execute_reply.started": "2024-02-17T16:48:10.829427Z",
          "shell.execute_reply": "2024-02-17T16:48:11.13273Z"
        },
        "trusted": true,
        "id": "H2v-WosAsQV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# results = trainer.predict(val_dataset)\n",
        "# predicted_labels = torch.argmax(torch.tensor(results.predictions), axis=1).numpy()\n",
        "accuracy = accuracy_score(references, predictions)\n",
        "f1 = f1_score(references, predictions, average=\"weighted\")\n",
        "\n",
        "print(f\"Validation Accuracy: {accuracy}\")\n",
        "print(f\"Validation F1 Score: {f1}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-17T16:48:16.774675Z",
          "iopub.execute_input": "2024-02-17T16:48:16.775166Z",
          "iopub.status.idle": "2024-02-17T16:48:16.78514Z",
          "shell.execute_reply.started": "2024-02-17T16:48:16.775132Z",
          "shell.execute_reply": "2024-02-17T16:48:16.784268Z"
        },
        "trusted": true,
        "id": "bgj6jFgUsQV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "answers_final = dict()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for f in tqdm(test_files):\n",
        "        key = f.split(\"/\")[-1].split(\".\")[0]\n",
        "\n",
        "        img = Image.open(f).convert(\"RGB\")\n",
        "        transformed = transforms[\"test\"](img).unsqueeze(0).to(device)\n",
        "        answers_final[key] = loaded_model(transformed).argmax(-1).item()\n",
        "\n",
        "answers_final"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-17T16:49:09.804807Z",
          "iopub.execute_input": "2024-02-17T16:49:09.805795Z",
          "iopub.status.idle": "2024-02-17T16:49:16.862269Z",
          "shell.execute_reply.started": "2024-02-17T16:49:09.805762Z",
          "shell.execute_reply": "2024-02-17T16:49:16.861245Z"
        },
        "trusted": true,
        "id": "1YdfkQEEsQV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/kaggle/input/ultra-wide-band-pose-prediction/sample_submission.csv\")\n",
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-17T16:49:23.02436Z",
          "iopub.execute_input": "2024-02-17T16:49:23.024893Z",
          "iopub.status.idle": "2024-02-17T16:49:23.046248Z",
          "shell.execute_reply.started": "2024-02-17T16:49:23.024853Z",
          "shell.execute_reply": "2024-02-17T16:49:23.045237Z"
        },
        "trusted": true,
        "id": "uqwkZcMUsQV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(df)):\n",
        "    file_name = df['id'][i]\n",
        "    df.loc[i, 'class'] = str(answers_final[file_name])\n",
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-17T16:53:03.401937Z",
          "iopub.execute_input": "2024-02-17T16:53:03.402752Z",
          "iopub.status.idle": "2024-02-17T16:53:03.43494Z",
          "shell.execute_reply.started": "2024-02-17T16:53:03.402723Z",
          "shell.execute_reply": "2024-02-17T16:53:03.433961Z"
        },
        "trusted": true,
        "id": "BHJ92bHIsQV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "old = pd.read_csv(\"/kaggle/working/seresnext.csv\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-17T16:52:53.936432Z",
          "iopub.execute_input": "2024-02-17T16:52:53.937384Z",
          "iopub.status.idle": "2024-02-17T16:52:53.946963Z",
          "shell.execute_reply.started": "2024-02-17T16:52:53.93734Z",
          "shell.execute_reply": "2024-02-17T16:52:53.945818Z"
        },
        "trusted": true,
        "id": "gAxlE5pZsQV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare = pd.concat([old['id'], old['class'], df['class']], axis=1)\n",
        "compare.columns=['id','old','new']\n",
        "compare['old'] = compare['old'].astype('string')\n",
        "compare[compare['old'] != compare['new']]\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-17T16:59:06.811319Z",
          "iopub.execute_input": "2024-02-17T16:59:06.811696Z",
          "iopub.status.idle": "2024-02-17T16:59:06.834069Z",
          "shell.execute_reply.started": "2024-02-17T16:59:06.811668Z",
          "shell.execute_reply": "2024-02-17T16:59:06.832979Z"
        },
        "trusted": true,
        "id": "BVUysVkasQV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(compare['old'][0]))\n",
        "print(type(compare['new'][0]))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-17T16:59:29.345163Z",
          "iopub.execute_input": "2024-02-17T16:59:29.345543Z",
          "iopub.status.idle": "2024-02-17T16:59:29.351128Z",
          "shell.execute_reply.started": "2024-02-17T16:59:29.345512Z",
          "shell.execute_reply": "2024-02-17T16:59:29.350166Z"
        },
        "trusted": true,
        "id": "On5tH445sQV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('seresnext.csv', index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-17T16:59:46.887316Z",
          "iopub.execute_input": "2024-02-17T16:59:46.887698Z",
          "iopub.status.idle": "2024-02-17T16:59:46.894891Z",
          "shell.execute_reply.started": "2024-02-17T16:59:46.887667Z",
          "shell.execute_reply": "2024-02-17T16:59:46.893888Z"
        },
        "trusted": true,
        "id": "qMWu5tfFsQV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ExcsEl-JsQV_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}